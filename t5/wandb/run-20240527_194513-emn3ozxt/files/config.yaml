wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.8.2
    cli_version: 0.17.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1716839113
    t:
      1:
      - 1
      - 5
      - 49
      - 50
      - 53
      - 55
      - 64
      2:
      - 1
      - 5
      - 49
      - 50
      - 53
      - 55
      - 64
      3:
      - 13
      - 23
      - 24
      - 61
      4: 3.8.2
      5: 0.17.0
      8:
      - 5
      - 9
      13: linux-x86_64
_name:
  desc: null
  value: null
common:
  desc: null
  value:
    _name: null
    no_progress_bar: false
    log_interval: 100
    log_format: json
    log_file: null
    aim_repo: null
    aim_run_hash: null
    tensorboard_logdir: null
    wandb_project: joint_training_en
    azureml_logging: false
    seed: 1
    cpu: false
    tpu: false
    bf16: false
    memory_efficient_bf16: false
    fp16: true
    memory_efficient_fp16: false
    fp16_no_flatten_grads: false
    fp16_init_scale: 128
    fp16_scale_window: null
    fp16_scale_tolerance: 0.0
    on_cpu_convert_precision: false
    min_loss_scale: 0.0001
    threshold_loss_scale: null
    amp: false
    amp_batch_retries: 2
    amp_init_scale: 128
    amp_scale_window: null
    user_dir: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/t5/artst
    empty_cache_freq: 0
    all_gather_list_size: 16384
    model_parallel_size: 1
    quantization_config_path: null
    profile: false
    reset_logging: false
    suppress_crashes: false
    use_plasma_view: false
    plasma_path: /tmp/plasma
common_eval:
  desc: null
  value:
    _name: null
    path: null
    post_process: sentencepiece
    quiet: false
    model_overrides: '{}'
    results_path: null
distributed_training:
  desc: null
  value:
    _name: null
    distributed_world_size: 2
    distributed_num_procs: 2
    distributed_rank: 0
    distributed_backend: nccl
    distributed_init_method: tcp://localhost:15135
    distributed_port: 0
    device_id: 0
    distributed_no_spawn: false
    ddp_backend: legacy_ddp
    ddp_comm_hook: none
    bucket_cap_mb: 25
    fix_batches_to_gpus: false
    find_unused_parameters: true
    gradient_as_bucket_view: false
    fast_stat_sync: false
    heartbeat_timeout: -1
    broadcast_buffers: false
    slowmo_momentum: null
    slowmo_base_algorithm: localsgd
    localsgd_frequency: 3
    nprocs_per_node: 2
    pipeline_model_parallel: false
    pipeline_balance: null
    pipeline_devices: null
    pipeline_chunks: 0
    pipeline_encoder_balance: null
    pipeline_encoder_devices: null
    pipeline_decoder_balance: null
    pipeline_decoder_devices: null
    pipeline_checkpoint: never
    zero_sharding: none
    fp16: true
    memory_efficient_fp16: false
    tpu: false
    no_reshard_after_forward: false
    fp32_reduce_scatter: false
    cpu_offload: false
    use_sharded_state: false
    not_fsdp_flatten_parameters: false
dataset:
  desc: null
  value:
    _name: null
    num_workers: 4
    skip_invalid_size_inputs_valid_test: true
    max_tokens: 3200000
    batch_size: null
    required_batch_size_multiple: 1
    required_seq_len_multiple: 1
    dataset_impl: null
    data_buffer_size: 10
    train_subset: train-clean-100|train-clean-360
    valid_subset: dev-clean|dev-clean
    combine_valid_subsets: null
    ignore_unused_valid_subsets: true
    validate_interval: 50
    validate_interval_updates: 0
    validate_after_updates: 10000
    fixed_validation_seed: null
    disable_validation: false
    max_tokens_valid: 3200000
    batch_size_valid: null
    max_valid_steps: null
    curriculum: 0
    gen_subset: test
    num_shards: 1
    shard_id: 0
    grouped_shuffling: false
    update_epoch_batch_itr: false
    update_ordered_indices_seed: false
optimization:
  desc: null
  value:
    _name: null
    max_epoch: 0
    max_update: 150000
    stop_time_hours: 0.0
    clip_norm: 25.0
    sentence_avg: true
    update_freq:
    - 4
    lr:
    - 0.0001
    stop_min_lr: -1.0
    use_bmuf: false
    skip_remainder_batch: false
checkpoint:
  desc: null
  value:
    _name: null
    save_dir: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/results/sttatts/models_english_150K_t5_new/
    restore_file: checkpoint_last.pt
    continue_once: null
    finetune_from_model: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/sttatts_en/speecht5_base.pt
    reset_dataloader: false
    reset_lr_scheduler: false
    reset_meters: false
    reset_optimizer: false
    optimizer_overrides: '{}'
    save_interval: 1
    save_interval_updates: 10000
    keep_interval_updates: -1
    keep_interval_updates_pattern: -1
    keep_last_epochs: 3
    keep_best_checkpoints: -1
    no_save: false
    no_epoch_checkpoints: false
    no_last_checkpoints: false
    no_save_optimizer_state: false
    best_checkpoint_metric: loss
    maximize_best_checkpoint_metric: false
    patience: -1
    checkpoint_suffix: ''
    checkpoint_shard_count: 1
    load_checkpoint_on_all_dp_ranks: false
    write_checkpoints_asynchronously: false
    model_parallel_size: 1
bmuf:
  desc: null
  value:
    _name: null
    block_lr: 1.0
    block_momentum: 0.875
    global_sync_iter: 50
    warmup_iterations: 500
    use_nbm: false
    average_sync: false
    distributed_world_size: 2
generation:
  desc: null
  value:
    _name: null
    beam: 5
    nbest: 1
    max_len_a: 0.0
    max_len_b: 200
    min_len: 1
    match_source_len: false
    unnormalized: false
    no_early_stop: false
    no_beamable_mm: false
    lenpen: 1.0
    unkpen: 0.0
    replace_unk: null
    sacrebleu: false
    score_reference: false
    prefix_size: 0
    no_repeat_ngram_size: 0
    sampling: false
    sampling_topk: -1
    sampling_topp: -1.0
    constraints: null
    temperature: 1.0
    diverse_beam_groups: -1
    diverse_beam_strength: 0.5
    diversity_rate: -1.0
    print_alignment: null
    print_step: false
    lm_path: null
    lm_weight: 0.0
    iter_decode_eos_penalty: 0.0
    iter_decode_max_iter: 10
    iter_decode_force_max_iter: false
    iter_decode_with_beam: 1
    iter_decode_with_external_reranker: false
    retain_iter_history: false
    retain_dropout: false
    retain_dropout_modules: null
    decoding_format: null
    no_seed_provided: false
    eos_token: null
eval_lm:
  desc: null
  value:
    _name: null
    output_word_probs: false
    output_word_stats: false
    context_window: 0
    softmax_batch: 9223372036854775807
interactive:
  desc: null
  value:
    _name: null
    buffer_size: 0
    input: '-'
criterion:
  desc: null
  value:
    _name: artst
    zero_infinity: true
    sentence_avg: true
    post_process: sentencepiece
    wer_kenlm_model: null
    wer_lexicon: null
    wer_lm_weight: 2.0
    wer_word_score: -1.0
    wer_args: null
    label_smoothing: 0.0
    report_accuracy: true
    ignore_prefix_size: 0
    ce_weight: 0.5
    ctc_weight: 0.5
    use_masking: true
    use_weighted_masking: false
    loss_type: L1
    bce_pos_weight: 5.0
    bce_loss_lambda: 1.0
    use_guided_attn_loss: true
    guided_attn_loss_sigma: 0.4
    guided_attn_loss_lambda: 10.0
    num_layers_applied_guided_attn: 2
    num_heads_applied_guided_attn: 2
    modules_applied_guided_attn:
    - encoder-decoder
    pred_masked_weight: 1.0
    pred_nomask_weight: 0.0
    loss_weights:
    - 0.1
    log_keys: []
    hubert_weight: 1.0
    dec_weight: 1.0
    bart_weight: 1.0
optimizer:
  desc: null
  value:
    _name: adam
    adam_betas: (0.9, 0.98)
    adam_eps: 1.0e-08
    weight_decay: 0.1
    use_old_adam: false
    fp16_adam_stats: false
    tpu: false
    lr:
    - 0.0001
lr_scheduler:
  desc: null
  value:
    _name: tri_stage
    warmup_steps: 10000
    hold_steps: 0
    decay_steps: 0
    phase_ratio:
    - 0.25
    - 0.4
    - 0.35
    init_lr_scale: 0.01
    final_lr_scale: 0.05
    max_update: 150000.0
    lr:
    - 0.0001
scoring:
  desc: null
  value:
    _name: bleu
    pad: 1
    eos: 2
    unk: 3
bpe:
  desc: null
  value: null
tokenizer:
  desc: null
  value: null
ema:
  desc: null
  value:
    _name: null
    store_ema: false
    ema_decay: 0.9999
    ema_start_update: 0
    ema_seed_model: null
    ema_update_freq: 1
    ema_fp32: false
args:
  desc: null
  value:
    no_progress_bar: false
    log_interval: 100
    log_format: json
    log_file: null
    aim_repo: null
    aim_run_hash: null
    tensorboard_logdir: null
    wandb_project: joint_training_en
    azureml_logging: false
    seed: 1
    cpu: false
    tpu: false
    bf16: false
    memory_efficient_bf16: false
    fp16: true
    memory_efficient_fp16: false
    fp16_no_flatten_grads: false
    fp16_init_scale: 128
    fp16_scale_window: null
    fp16_scale_tolerance: 0.0
    on_cpu_convert_precision: false
    min_loss_scale: 0.0001
    threshold_loss_scale: null
    amp: false
    amp_batch_retries: 2
    amp_init_scale: 128
    amp_scale_window: null
    user_dir: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/t5/artst
    empty_cache_freq: 0
    all_gather_list_size: 16384
    model_parallel_size: 1
    quantization_config_path: null
    profile: false
    reset_logging: false
    suppress_crashes: false
    use_plasma_view: false
    plasma_path: /tmp/plasma
    criterion: artst
    tokenizer: null
    bpe: null
    optimizer: adam
    lr_scheduler: tri_stage
    scoring: bleu
    task: artst
    num_workers: 4
    skip_invalid_size_inputs_valid_test: true
    max_tokens: 3200000
    batch_size: null
    required_batch_size_multiple: 1
    required_seq_len_multiple: 1
    dataset_impl: null
    data_buffer_size: 10
    train_subset: train-clean-100|train-clean-360
    valid_subset: dev-clean|dev-clean
    combine_valid_subsets: null
    ignore_unused_valid_subsets: true
    validate_interval: 50
    validate_interval_updates: 0
    validate_after_updates: 10000
    fixed_validation_seed: null
    disable_validation: false
    max_tokens_valid: 3200000
    batch_size_valid: null
    max_valid_steps: null
    curriculum: 0
    gen_subset: test
    num_shards: 1
    shard_id: 0
    grouped_shuffling: false
    update_epoch_batch_itr: false
    update_ordered_indices_seed: false
    distributed_world_size: 2
    distributed_num_procs: 2
    distributed_rank: 0
    distributed_backend: nccl
    distributed_init_method: null
    distributed_port: 0
    device_id: 0
    distributed_no_spawn: false
    ddp_backend: legacy_ddp
    ddp_comm_hook: none
    bucket_cap_mb: 25
    fix_batches_to_gpus: false
    find_unused_parameters: true
    gradient_as_bucket_view: false
    fast_stat_sync: false
    heartbeat_timeout: -1
    broadcast_buffers: false
    slowmo_momentum: null
    slowmo_base_algorithm: localsgd
    localsgd_frequency: 3
    nprocs_per_node: 2
    pipeline_model_parallel: false
    pipeline_balance: null
    pipeline_devices: null
    pipeline_chunks: 0
    pipeline_encoder_balance: null
    pipeline_encoder_devices: null
    pipeline_decoder_balance: null
    pipeline_decoder_devices: null
    pipeline_checkpoint: never
    zero_sharding: none
    no_reshard_after_forward: false
    fp32_reduce_scatter: false
    cpu_offload: false
    use_sharded_state: false
    not_fsdp_flatten_parameters: false
    arch: artst_transformer_base_asr
    max_epoch: 0
    max_update: 150000
    stop_time_hours: 0
    clip_norm: 25.0
    sentence_avg: true
    update_freq:
    - 4
    lr:
    - 0.0001
    stop_min_lr: -1.0
    use_bmuf: false
    skip_remainder_batch: false
    save_dir: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/results/sttatts/models_english_150K_t5_new/
    restore_file: checkpoint_last.pt
    continue_once: null
    finetune_from_model: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/sttatts_en/speecht5_base.pt
    reset_dataloader: false
    reset_lr_scheduler: false
    reset_meters: false
    reset_optimizer: false
    optimizer_overrides: '{}'
    save_interval: 1
    save_interval_updates: 10000
    keep_interval_updates: -1
    keep_interval_updates_pattern: -1
    keep_last_epochs: 3
    keep_best_checkpoints: -1
    no_save: false
    no_epoch_checkpoints: false
    no_last_checkpoints: false
    no_save_optimizer_state: false
    best_checkpoint_metric: loss
    maximize_best_checkpoint_metric: false
    patience: -1
    checkpoint_suffix: ''
    checkpoint_shard_count: 1
    load_checkpoint_on_all_dp_ranks: false
    write_checkpoints_asynchronously: false
    store_ema: false
    ema_decay: 0.9999
    ema_start_update: 0
    ema_seed_model: null
    ema_update_freq: 1
    ema_fp32: false
    encoder_sliding_window_attn: null
    encoder_speech_prenet: conv
    conv_kernel_sizes: 5,5
    conv_channels: 1024
    subsample_stride: 2,2
    dprenet_dropout_rate: 0.5
    se_predict: null
    se_decoder_input: previous_target
    modules_filter: null
    encoder_attn_branch: identity,full
    sid_encoder_cls: null
    sid_decoder_attn_dim: 128
    sid_embed_dim: 128
    sid_pooling_layer: decoder
    sid_softmax_type: softmax
    softmax_scale: 1.0
    softmax_margin: 0.0
    num_buckets: 320
    max_distance: 1280
    unb_enc_layer: -1
    data: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/sttatts_en
    config_yaml: config.yaml
    asr_dir: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/librispeech_cleaned_manifest
    tts_dir: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/libritts_cleaned_manifest
    max_speech_sample_size: 480256
    min_speech_sample_size: 1056
    max_speech_positions: 1876
    max_text_positions: 600
    t5_task: multitask
    bpe_tokenizer: /fsx/hyperpod-input-datasets/AROA6GBMFKRI2VWQAUGYI:Hawau.Toyin@mbzuai.ac.ae/sttatts_en/spm_char.model
    finetune_from_modules: null
    finetune_out_of_modules: null
    shorten_method: none
    shorten_data_split_list: ''
    tokens_per_sample: 512
    sample_break_mode: eos
    mask: 0.3
    mask_random: 0.1
    insert: 0.0
    permute: 0.0
    rotate: 0.0
    poisson_lambda: 3.5
    permute_sentences: 0.0
    replace_length: 1
    iid_noise_target: false
    hubert_labels:
    - km
    hubert_label_dir: null
    sample_rate: 16000.0
    label_rates: -1
    normalize: false
    enable_padding: false
    pad_audio: false
    random_crop: false
    single_target: false
    batch_ratio: '[0.5,0.5]'
    sample_ratios: '[0.5,0.5]'
    ctc_weight: 0.5
    inference_speech: false
    zero_infinity: true
    post_process: sentencepiece
    wer_kenlm_model: null
    wer_lexicon: null
    wer_lm_weight: 2.0
    wer_word_score: -1.0
    wer_args: null
    label_smoothing: 0.0
    report_accuracy: true
    ignore_prefix_size: 0
    ce_weight: 0.5
    use_masking: true
    use_weighted_masking: false
    loss_type: L1
    bce_pos_weight: 5.0
    bce_loss_lambda: 1.0
    use_guided_attn_loss: true
    guided_attn_loss_sigma: 0.4
    guided_attn_loss_lambda: 10.0
    num_layers_applied_guided_attn: 2
    num_heads_applied_guided_attn: 2
    modules_applied_guided_attn:
    - encoder-decoder
    pred_masked_weight: 1.0
    pred_nomask_weight: 0.0
    loss_weights:
    - 0.1
    log_keys: []
    hubert_weight: 1.0
    dec_weight: 1.0
    bart_weight: 1.0
    adam_betas: (0.9, 0.98)
    adam_eps: 1.0e-08
    weight_decay: 0.1
    use_old_adam: false
    fp16_adam_stats: false
    warmup_steps: 10000
    hold_steps: 0
    decay_steps: 0
    phase_ratio:
    - 0.25
    - 0.4
    - 0.35
    init_lr_scale: 0.01
    final_lr_scale: 0.05
    pad: 1
    eos: 2
    unk: 3
    share_input_output_embed: true
    bert_init: true
    relative_position_embedding: true
    feature_grad_mult: 1.0
    no_seed_provided: false
    use_conv_pos: true
    use_sinc_pos: true
    encoder_normalize_before: false
    decoder_normalize_before: false
    layer_norm_first: false
    dropout: 0.1
    activation_dropout: 0.1
    attention_dropout: 0.1
    encoder_layerdrop: 0.1
    decoder_layerdrop: 0.1
    mask_prob: 0.75
    mask_selection: static
    mask_channel_length: 64
    mask_channel_prob: 0.5
    mask_channel_selection: static
    encoder_embed_dim: 768
    encoder_ffn_embed_dim: 3072
    encoder_layers: 12
    encoder_attention_heads: 12
    decoder_embed_dim: 768
    decoder_ffn_embed_dim: 3072
    decoder_layers: 6
    decoder_attention_heads: 12
    activation_fn: gelu
    decoder_output_dim: 768
    decoder_input_dim: 768
    eprenet_conv_layers: 0
    eprenet_conv_filts: 0
    eprenet_conv_chans: 0
    use_batch_norm: true
    eprenet_dropout_rate: 0.0
    enc_use_scaled_pos_enc: true
    dec_use_scaled_pos_enc: true
    postnet_layers: 5
    postnet_chans: 256
    postnet_filts: 5
    postnet_dropout_rate: 0.5
    dprenet_layers: 2
    dprenet_units: 256
    initial_encoder_alpha: 1.0
    initial_decoder_alpha: 1.0
    spk_embed_integration_type: pre
    spk_embed_dim: 512
    encoder_reduction_factor: 1
    reduction_factor: 2
    transformer_enc_positional_dropout_rate: 0.1
    transformer_dec_positional_dropout_rate: 0.1
    layer_norm_eps: 1.0e-05
    no_scale_embedding: true
    quant_noise_pq: 0
    adaptive_softmax_cutoff: null
    adaptive_softmax_dropout: 0
    no_token_positional_embeddings: false
    adaptive_input: false
    decoder_learned_pos: false
    share_ctc_embed: false
    freeze_encoder_updates: 0
    freeze_decoder_updates: 0
    no_freeze_encoder_layer: null
    softmax_easy_margin: false
    conv_pos: 128
    conv_pos_groups: 16
    target_glu: false
    logit_temp: 0.1
    final_dim: 256
    untie_final_proj: true
    use_sent_enc_layer: true
    extractor_mode: default
    conv_feature_layers: '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2'
    conv_bias: false
    hubert_mask_length: 10
    mask_other: 0
    no_mask_overlap: false
    mask_min_space: 1
    mask_channel_other: 0
    no_mask_channel_overlap: false
    mask_channel_min_space: 1
    skip_masked: false
    skip_nomask: false
    use_codebook: false
    latent_vars: 100
    latent_groups: 2
    latent_dim: 0
    latent_temp:
    - 2
    - 0.5
    - 0.999995
    quantizer_depth: 1
    quantizer_factor: 3
    codebook_prob: 0.5
    encoder_max_relative_position: 160
    decoder_max_relative_position: 160
    _name: artst
